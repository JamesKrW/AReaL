{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c66c6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict, dataclass\n",
    "\n",
    "from areal.api.agent_args import AgentGRPOConfig, load_expr_config\n",
    "\n",
    "args = [\"--config\", \"AReaL/examples/lite/configs/sokoban_grpo.yaml\"]\n",
    "config, _ = load_expr_config(args, AgentGRPOConfig)\n",
    "config: AgentGRPOConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24455ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from areal.utils.network import find_free_ports\n",
    "\n",
    "SGLANG_PORT, MASTER_PORT = 11451, 14514\n",
    "\n",
    "SGLANG_HOST = \"127.0.0.1\"\n",
    "\n",
    "# Environment variables used by inference/train engines\n",
    "import os\n",
    "\n",
    "os.environ[\"AREAL_LLM_SERVER_ADDRS\"] = f\"{SGLANG_HOST}:{SGLANG_PORT}\"\n",
    "os.environ[\"MASTER_ADDR\"] = \"127.0.0.1\"\n",
    "os.environ[\"MASTER_PORT\"] = str(MASTER_PORT)\n",
    "os.environ[\"RANK\"] = str(0)\n",
    "os.environ[\"WORLD_SIZE\"] = str(1)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "os.environ[\"LOCAL_RANK\"] = str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# 启动sglang server\n",
    "from areal.api.cli_args import SGLangConfig\n",
    "from areal.utils.network import find_free_ports\n",
    "\n",
    "config.sglang.log_level = \"info\"\n",
    "config.sglang.decode_log_interval = 10\n",
    "sglang_cmd = SGLangConfig.build_cmd(\n",
    "    config.sglang,\n",
    "    tp_size=1,\n",
    "    base_gpu_id=1,\n",
    "    host=SGLANG_HOST,\n",
    "    port=SGLANG_PORT,\n",
    ")\n",
    "sglang_process = subprocess.Popen(\n",
    "    sglang_cmd,\n",
    "    shell=True,\n",
    "    stdout=sys.stdout,\n",
    "    stderr=sys.stderr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import functools\n",
    "import os\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "import colorama\n",
    "import torch\n",
    "from tensordict import TensorDict\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizerFast\n",
    "\n",
    "from areal.api.cli_args import GenerationHyperparameters\n",
    "from areal.api.engine_api import InferenceEngine\n",
    "from areal.api.io_struct import (\n",
    "    AllocationMode,\n",
    "    FinetuneSpec,\n",
    "    LLMRequest,\n",
    "    WeightUpdateMeta,\n",
    ")\n",
    "from areal.api.workflow_api import RolloutWorkflow\n",
    "from areal.engine.ppo.actor import FSDPPPOActor\n",
    "from areal.engine.sglang_remote import RemoteSGLangEngine\n",
    "from areal.utils.data import concat_padded_tensors\n",
    "from areal.utils.device import log_gpu_stats\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.tokenizer_path)\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0be646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdata.stateful_dataloader import StatefulDataLoader\n",
    "from areal.dataset.multi_env_dataset import build_env_dataset\n",
    "rank=0\n",
    "world_size = 1\n",
    "train_dataset = build_env_dataset(\n",
    "        config.envs, split=\"train\", base_seed=config.seed, rank=rank, world_size=world_size\n",
    "    )\n",
    "dataloader = StatefulDataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.train_dataset.batch_size // world_size,\n",
    "        shuffle=config.train_dataset.shuffle,\n",
    "        num_workers=config.train_dataset.num_workers,\n",
    "        collate_fn=lambda x: x,\n",
    "        drop_last=config.train_dataset.drop_last,\n",
    "    )\n",
    "\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "data_generator = cycle(dataloader)\n",
    "\n",
    "ft_spec = FinetuneSpec(\n",
    "    total_train_epochs=config.total_train_epochs,\n",
    "    dataset_size=len(dataloader) * config.train_dataset.batch_size,\n",
    "    train_batch_size=config.train_dataset.batch_size,\n",
    ")\n",
    "\n",
    "x = next(data_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792131d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[0])\n",
    "print(x[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b103ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AREAL_DEBUG_TOKEN_ALIGN\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be29d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize inference engine\n",
    "from areal.engine.sglang_remote import RemoteSGLangEngine\n",
    "from areal.workflow.multi_turn_agent_env_workflow import MultiTurnAgentEnvWorkflow\n",
    "rollout = RemoteSGLangEngine(config.rollout)\n",
    "rollout.initialize(None, None)\n",
    "try:\n",
    "    # TODO: create workflow\n",
    "    workflow = MultiTurnAgentEnvWorkflow(\n",
    "        gconfig=GenerationHyperparameters(n_samples=3,max_new_tokens=512),\n",
    "        tokenizer=tokenizer,\n",
    "        max_turns=3,\n",
    "        dump_dir=\"./test\"\n",
    "    )\n",
    "    sample_data = next(data_generator)[:2]\n",
    "    res = rollout.rollout_batch(sample_data, workflow=workflow)\n",
    "    print(res)\n",
    "finally:\n",
    "    rollout.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = MultiTurnAgentEnvWorkflow(\n",
    "        gconfig=GenerationHyperparameters(n_samples=3,max_new_tokens=512),\n",
    "        tokenizer=tokenizer,\n",
    "        max_turns=3,\n",
    "        dump_dir=\"./test\"\n",
    "    )\n",
    "actor = FSDPPPOActor(config=config.actor)\n",
    "actor.initialize(None, ft_spec)\n",
    "\n",
    "rollout = RemoteSGLangEngine(config.rollout)\n",
    "rollout.initialize(None, None)\n",
    "\n",
    "weight_update_meta = WeightUpdateMeta.from_fsdp_nccl(\n",
    "    AllocationMode.from_str(\"sglang.d1p1t1+d1p1t1\"), actor\n",
    ")\n",
    "\n",
    "warmup_steps = 1\n",
    "times = []\n",
    "for global_step in range(5):\n",
    "    if global_step >= warmup_steps:\n",
    "        tik = time.perf_counter()\n",
    "    batch = rollout.rollout_batch(next(data_generator), workflow=workflow)\n",
    "    batch = batch.to(actor.device)\n",
    "\n",
    "    logp = actor.compute_logp(batch)\n",
    "    batch[\"prox_logp\"] = logp\n",
    "\n",
    "    actor.compute_advantages(batch)\n",
    "\n",
    "    stats = actor.ppo_update(batch)\n",
    "    actor.step_lr_scheduler()\n",
    "\n",
    "    rollout.pause()\n",
    "    future = rollout.update_weights(weight_update_meta)\n",
    "    actor.upload_weights(weight_update_meta)\n",
    "    future.result()\n",
    "    torch.cuda.synchronize()\n",
    "    rollout.resume()\n",
    "\n",
    "    actor.set_version(global_step + 1)\n",
    "    rollout.set_version(global_step + 1)\n",
    "    if global_step >= warmup_steps:\n",
    "        times.append(time.perf_counter() - tik)\n",
    "print(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = MultiTurnAgentEnvWorkflow(\n",
    "        gconfig=GenerationHyperparameters(n_samples=3,max_new_tokens=512),\n",
    "        tokenizer=tokenizer,\n",
    "        max_turns=3,\n",
    "        dump_dir=\"./test\"\n",
    "    )\n",
    "actor = FSDPPPOActor(config=config.actor)\n",
    "actor.initialize(None, ft_spec)\n",
    "\n",
    "rollout = RemoteSGLangEngine(config.rollout)\n",
    "rollout.initialize(None, None)\n",
    "\n",
    "weight_update_meta = WeightUpdateMeta.from_fsdp_nccl(\n",
    "    AllocationMode.from_str(\"sglang.d1p1t1+d1p1t1\"), actor\n",
    ")\n",
    "weight_update_meta.nccl_group_name = \"group2\"\n",
    "\n",
    "warmup_steps = 1\n",
    "times = []\n",
    "for global_step in range(5):\n",
    "    if global_step >= warmup_steps:\n",
    "        tik = time.perf_counter()\n",
    "    batch = rollout.prepare_batch(dataloader, workflow=workflow)\n",
    "    batch = batch.to(actor.device)\n",
    "\n",
    "    logp = actor.compute_logp(batch)\n",
    "    batch[\"prox_logp\"] = logp\n",
    "\n",
    "    actor.compute_advantages(batch)\n",
    "\n",
    "    stats = actor.ppo_update(batch)\n",
    "    actor.step_lr_scheduler()\n",
    "\n",
    "    rollout.pause()\n",
    "    future = rollout.update_weights(weight_update_meta)\n",
    "    actor.upload_weights(weight_update_meta)\n",
    "    future.result()\n",
    "    torch.cuda.synchronize()\n",
    "    rollout.resume()\n",
    "\n",
    "    actor.set_version(global_step + 1)\n",
    "    rollout.set_version(global_step + 1)\n",
    "    if global_step >= warmup_steps:\n",
    "        times.append(time.perf_counter() - tik)\n",
    "print(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal as signal_module\n",
    "\n",
    "import psutil\n",
    "\n",
    "\n",
    "def terminate_process_and_children(pid: int, signal=None):\n",
    "    if signal is None:\n",
    "        signal = signal_module.SIGKILL\n",
    "    if isinstance(signal, str):\n",
    "        signal = getattr(signal_module, signal)\n",
    "    try:\n",
    "        parent = psutil.Process(pid)\n",
    "        children = parent.children(recursive=True)\n",
    "        for child in children:\n",
    "            terminate_process_and_children(child.pid)\n",
    "        parent.send_signal(signal)\n",
    "    except psutil.NoSuchProcess:\n",
    "        pass\n",
    "\n",
    "\n",
    "terminate_process_and_children(sglang_process.pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "areal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
